{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unify into one dictionary\n",
    "#These are charity mission statements that can be matched against posts/comments\n",
    "with open('orgID_missionDict.pickle', 'rb') as handle1:\n",
    "    orgID_missionDict = pickle.load(handle1)\n",
    "    \n",
    "with open('orgID_websiteDict.pickle', 'rb') as handle2:\n",
    "    orgID_websiteDict = pickle.load(handle2)\n",
    "    \n",
    "with open('orgID_NameDict.pickle', 'rb') as handle3:\n",
    "    orgID_NameDict = pickle.load(handle3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import nltk components to use for matching (TF) instance\n",
    "#Can substitute other models here\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "#Get stem funciton\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "#Get stems, remove punctuation, transform lower case\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')\n",
    "\n",
    "def cosine_sim(text1, text2):\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0,1] #positions in the matrix for the similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Register Credentials\n",
    "reddit = praw.Reddit(client_id=\"******\",\n",
    "                     client_secret=\"******\",\n",
    "                     user_agent=\"******\",\n",
    "                     username = '******',\n",
    "                     password = '******')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "subreddit = reddit.subreddit(\"test\")\n",
    "\n",
    "#For basic usage to attain submission titles/selftext \n",
    "#and highest level comments\n",
    "#for submission in subreddit.hot(limit=10):\n",
    "value_list_nltk = []\n",
    "#Stream usage otherwise same as basic usage\n",
    "for submission in subreddit.stream.submissions():\n",
    "\n",
    "    submission_title = submission.title\n",
    "    submission_selftext = submission.selftext\n",
    "    \n",
    "    #submission_flairID = submission.link_flair_template_id\n",
    "    #submission_flairText = submission.link_flair_text\n",
    "    \n",
    "    if \"!charitybot\" in submission_title or \"!charitybot\" in submission_selftext:\n",
    "        print(\"word charity found\")\n",
    "        #submission.reply(reply_text)\n",
    "        \n",
    "        for key, value in orgID_missionDict.items():\n",
    "            #value_list.append(charity_text.similarity(nlp(value)))\n",
    "            value_list_nltk.append([cosine_sim(submission_selftext, value), key])\n",
    "    \n",
    "        value_list_sorted = sorted(value_list_nltk, key=itemgetter(0))\n",
    "        \n",
    "        \n",
    "        first_Recom_key = value_list_sorted[-1][1]\n",
    "        second_Recom_key = value_list_sorted[-2][1]\n",
    "        third_Recom_key = value_list_sorted[-3][1]\n",
    "        \n",
    "        interest_text = \"The following organization(s) may be of interest to you: <br>\"\n",
    "        first_Recom_Mission = orgID_missionDict[first_Recom_key]\n",
    "        first_Recom_URL = orgID_websiteDict[first_Recom_key]\n",
    "        first_Recom_Name = orgID_NameDict[first_Recom_key]\n",
    "        \n",
    "        submission.reply(interest_text + first_Recom_Name + \" : \"  + first_Recom_URL + \"\\n\" + \" Mission Statement: \"\\\n",
    "                        + first_Recom_Mission)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"recommendation submitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
