{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Different File Types Require Different Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import lzma\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Procedure for File Type .XZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"RC_2018-01.xz\"\n",
    "\n",
    "total_number_of_comments = 0 \n",
    "total_number_of_comments_by_subreddit = {} \n",
    "keyword_occurrence_by_subreddit = {}\n",
    "relevant_comment_bodies = []\n",
    "subreddits_of_interest_JSON = []\n",
    "\n",
    "\n",
    "with lzma.open(filename, 'rt') as input: \n",
    "    for line in input: \n",
    "        comment = json.loads(line)\n",
    "        \n",
    "        #Keep Track of Total Number of Comments\n",
    "        total_number_of_comments += 1\n",
    "        \n",
    "        \n",
    "        #Total Number of Comments by Subreddit\n",
    "        if comment[\"subreddit\"] not in total_number_of_comments_by_subreddit:\n",
    "            total_number_of_comments_by_subreddit[comment[\"subreddit\"]] = 1\n",
    "        else:\n",
    "            total_number_of_comments_by_subreddit[comment[\"subreddit\"]] += 1\n",
    "        \n",
    "        \n",
    "        #Occurrence of Keywords by Subreddit\n",
    "        if \"charity\" in comment[\"body\"].lower() or \"donation\" in comment[\"body\"].lower() or \\\n",
    "        \"donate\" in comment[\"body\"].lower():\n",
    "            if comment[\"subreddit\"] not in keyword_occurrence_by_subreddit:\n",
    "                keyword_occurrence_by_subreddit[comment[\"subreddit\"]] = 1\n",
    "            else:\n",
    "                keyword_occurrence_by_subreddit[comment[\"subreddit\"]] += 1\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        #Collect Comment Bodies for later Review\n",
    "        if \"unicef\" in comment[\"body\"].lower() or \"international rescue committee\" in comment[\"body\"].lower() or \\\n",
    "        \"oxfam\" in comment[\"body\"].lower() or \"doctors without borders\" in comment[\"body\"].lower():\n",
    "            relevant_comment_bodies.append([comment[\"body\"], comment[\"id\"], comment[\"score\"], comment[\"subreddit\"]])\n",
    "            \n",
    "        \n",
    "        \n",
    "        #Build JSON Files for Subreddits of Interest\n",
    "        list_of_subreddits_of_interest = [\"worldnews\", \n",
    "                                          \"news\", \n",
    "                                          \"iama\",\n",
    "                                          \"upliftingnews\", \n",
    "                                          \"wholesomememes\",\n",
    "                                          \"animalsbeingbros\",\n",
    "                                          \"aww\",\n",
    "                                          \"cats\",\n",
    "                                          \"dogs\",\n",
    "                                          \"awwducational\",\n",
    "                                          \"likeus\"]\n",
    "        \n",
    "        if comment[\"subreddit\"] in list_of_subreddits_of_interest:\n",
    "            subreddits_of_interest_JSON.append([comment])\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('total_number_of_comments_by_subreddit_01.pickle', 'wb') as handle:\n",
    "    pickle.dump(total_number_of_comments_by_subreddit, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('keyword_occurrence_by_subreddit_01.pickle', 'wb') as handle:\n",
    "    pickle.dump(keyword_occurrence_by_subreddit, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('relevant_comment_bodies_01.pickle', 'wb') as handle:\n",
    "    pickle.dump(relevant_comment_bodies, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('subreddits_of_interest_JSON_01.pickle', 'wb') as handle:\n",
    "    pickle.dump(subreddits_of_interest_JSON, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "###Procedure for File Type .ZSTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zstd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"filename.zst\", 'rb') as fh:\n",
    "\n",
    "    dctx = zstd.ZstdDecompressor()\n",
    "    with dctx.stream_reader(fh) as reader:\n",
    "        previous_line = \"\"\n",
    "        while True:\n",
    "            chunk = reader.read(65536)\n",
    "            if not chunk:\n",
    "                break\n",
    "\n",
    "            string_data = chunk.decode('utf-8')\n",
    "            lines = string_data.split(\"\\n\")\n",
    "            for i, line in enumerate(lines[:-1]):\n",
    "                if i == 0:\n",
    "                    line = previous_line + line\n",
    "                object = json.loads(line)\n",
    "                \n",
    "                # process object here\n",
    "            previous_line = lines[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###For Files Before 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"jsonfile.json\") as fh:\n",
    "    data = json.loads(\"[\" + \n",
    "        f.read().replace(\"}\\n{\", \"},\\n{\") + \n",
    "    \"]\")\n",
    "    \n",
    "#pprint(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
