{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook contains Word2Vec Embedding Procedures on Pre-Trained and Custum Corpuses and Tests Performed on Word2Vec to Determine How it Performs on Text Similarity Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"missionStatements.pickle\"\n",
    "\n",
    "with open(filename, \"rb\") as handle:\n",
    "    missionStatements = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_format = []\n",
    "\n",
    "for k, v in missionStatements.items():\n",
    "    df_format.append([k, v[3]])\n",
    "    \n",
    "df = pd.DataFrame(df_format, columns = ['orgID', 'missionStatement']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    \n",
    "    # remove stop words\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    # remove punctuation\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train Word2Vec Model and Create Dictionary for Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for words in df['missionStatement']:\n",
    "    words = text_preprocessing(words)\n",
    "    corpus.append(words.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "google_word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "\n",
    "# Training the corpus with Google Pretrained Model\n",
    "google_model = Word2Vec(size = 300, window = 5, min_count = 2, workers = -1)\n",
    "google_model.build_vocab(corpus)\n",
    "\n",
    "google_model.intersect_word2vec_format(EMBEDDING_FILE, lockf=1.0, binary=True)\n",
    "google_model.train(corpus, total_examples = google_model.corpus_count, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to retrieve Word2Vec Embeddings\n",
    "\n",
    "def getWord2Vec_Embedding(text):\n",
    "    \n",
    "    avgword2vec = None\n",
    "    count = 0\n",
    "    \n",
    "    for word in text.split():\n",
    "        \n",
    "        if word in google_model.wv.vocab:\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "            if avgword2vec is None:\n",
    "                avgword2vec = google_model[word]\n",
    "            else:\n",
    "                avgword2vec = avgword2vec + google_model[word]\n",
    "                \n",
    "    if avgword2vec is not None:\n",
    "        avgword2vec = avgword2vec / count\n",
    "        \n",
    "        return avgword2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for word embeddings\n",
    "\n",
    "word2Vec_Embeddings = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    orgID = row['orgID']\n",
    "    missionStatement = row['missionStatement']\n",
    "    # to use with word preprocessing\n",
    "    #missionStatement = text_preprocessing(row['missionStatement'])\n",
    "    \n",
    "    \n",
    "    vectors = getWord2Vec_Embedding(missionStatement)\n",
    "    word2Vec_Embeddings[orgID] = vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing Section: This section presents several tests. In order to run on different models, substitute in the appropriate dictionaries from Section 1. \n",
    "\n",
    "### Specifically, what the tests do is to take a mission statement from a charity, manipulate the mission statement, e.g. delete parts, add noise, etc., and see if the altered mission statement is successfully matched with the organization's original/unaltered mission statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from operator import itemgetter\n",
    "from nltk.corpus import wordnet\n",
    "from scipy.spatial.distance import cosine\n",
    "from randomwordgenerator import randomwordgenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. This is just a check to see that everything works. The mission statement is not altered. The unaltered statement is matched with the closest mission statement (it should be itself)  - hundred percent match should be attained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of in/correct matches\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "# loop over mission statements\n",
    "for k, v in missionStatements.items():\n",
    "\n",
    "    missionStatement = v[3]\n",
    "    orgID = k\n",
    "    \n",
    "    # generate w2v word embedding for altered mission statement\n",
    "    w2v_missionStatement = getWord2Vec_Embedding(missionStatement)\n",
    "    collect_Cosine_Values = []\n",
    "\n",
    "    for key, value in word2Vec_Embeddings_cleanedStatements.items():\n",
    "        \n",
    "        cosim = 1 - cosine(value, w2v_missionStatement)\n",
    "        collect_Cosine_Values.append([cosim, key])\n",
    "\n",
    "    value_list_sorted = sorted(collect_Cosine_Values, key=itemgetter(0))\n",
    "\n",
    "    if value_list_sorted[-1][1] == orgID:\n",
    "        correct_count += 1        \n",
    "    else:\n",
    "        incorrect_count += 1\n",
    "        \n",
    "percent = correct_count/(correct_count + incorrect_count) *100\n",
    "print(percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. This is the first manipulation. A fraction of the mission statement is selected (either 1/2, 1/5, or 1/10) and then attempted to match with the closest unaltered mission statement. If it is matched with its unaltered version, it's recorded as a correct match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of in/correct matches\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "# loop over mission statements\n",
    "for k, v in missionStatements.items():\n",
    "\n",
    "    missionStatement = v[3]\n",
    "    orgID = k\n",
    "\n",
    "    # vary length of statement e.g. first half, first tenth, second half, etc\n",
    "    missionStatement_length = len(missionStatement)\n",
    "    missionStatement = missionStatement[:int(0.5*missionStatement_length)]\n",
    "        \n",
    "    # generate w2v word embedding for altered mission statement\n",
    "    w2v_missionStatement = getWord2Vec_Embedding(missionStatement)\n",
    "    collect_Cosine_Values = []\n",
    "\n",
    "    for key, value in word2Vec_Embeddings_cleanedStatements.items():\n",
    "        \n",
    "        cosim = 1 - cosine(value, w2v_missionStatement)\n",
    "        collect_Cosine_Values.append([cosim, key])\n",
    "\n",
    "    value_list_sorted = sorted(collect_Cosine_Values, key=itemgetter(0))\n",
    "\n",
    "    if value_list_sorted[-1][1] == orgID:\n",
    "        correct_count += 1        \n",
    "    else:\n",
    "        incorrect_count += 1\n",
    "        \n",
    "percent = correct_count/(correct_count + incorrect_count) *100\n",
    "print(percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. This test selects a random subset of words from the mission statement and only uses these words in its attempt to match with the correct un-altered mission statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of in/correct matches\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "# loop over mission statements\n",
    "for k, v in missionStatements.items():\n",
    "\n",
    "    missionStatement = v[3]\n",
    "    orgID = k\n",
    "    \n",
    "    # select random subset of words from mission statement\n",
    "    # convert mission statement into list of words\n",
    "    missionStatementWords_asList = missionStatement.split()\n",
    "\n",
    "    # get number of words in mission statement\n",
    "    no_words = len(missionStatementWords_asList)\n",
    "    half_no_words = int(no_words*0.5)\n",
    "\n",
    "    # list to populate with random words from mission statement\n",
    "    select_Words_atRandom = []\n",
    "\n",
    "    while len(select_Words_atRandom) < half_no_words:\n",
    "\n",
    "        randno = random.randint(0, no_words-1)\n",
    "        word = missionStatementWords_asList[randno]\n",
    "\n",
    "        # Non-Unique Version \n",
    "        select_Words_atRandom.append(word)\n",
    "        \n",
    "        # Unique Version: this version prevents duplicates to be in new statement\n",
    "        #if word not in select_Words_atRandom:\n",
    "        #    select_Words_atRandom.append(word)\n",
    "        #else:\n",
    "        #    pass\n",
    "\n",
    "    constructed_missionStatement = \" \".join(select_Words_atRandom)\n",
    "    missionStatement = constructed_missionStatement\n",
    "    \n",
    "    # generate w2v word embedding for altered mission statement\n",
    "    w2v_missionStatement = getWord2Vec_Embedding(missionStatement)\n",
    "    collect_Cosine_Values = []\n",
    "\n",
    "    for key, value in word2Vec_Embeddings_cleanedStatements.items():\n",
    "        \n",
    "        cosim = 1 - cosine(value, w2v_missionStatement)\n",
    "        collect_Cosine_Values.append([cosim, key])\n",
    "\n",
    "    value_list_sorted = sorted(collect_Cosine_Values, key=itemgetter(0))\n",
    "\n",
    "    if value_list_sorted[-1][1] == orgID:\n",
    "        correct_count += 1        \n",
    "    else:\n",
    "        incorrect_count += 1\n",
    "        \n",
    "percent = correct_count/(correct_count + incorrect_count) *100\n",
    "print(percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. This test attempts to measure how noise affects the algorithms performance. Fraction of the original mission statement is replaced with random words (noise). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of in/correct matches\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "# loop over mission statements\n",
    "for k, v in missionStatements.items():\n",
    "\n",
    "    missionStatement = v[3]\n",
    "    orgID = k\n",
    "    \n",
    "    # Substitute fraction of mission statement with random words approximating noise\n",
    "    missionStatementWords_asList = missionStatement.split()\n",
    "\n",
    "    no_words = len(missionStatementWords_asList)\n",
    "    fraction_of_words = int(no_words * (1/2))\n",
    "\n",
    "    firstPart = missionStatementWords_asList[:fraction_of_words + 1]\n",
    "    secondPart = randomwordgenerator.generate_random_words(n = int(no_words * (1/2)))\n",
    "\n",
    "    constructed_missionStatement1 = \" \".join(firstPart)\n",
    "    constructed_missionStatement2 = \" \".join(secondPart)\n",
    "    missionStatement = constructed_missionStatement1 + \" \" + constructed_missionStatement2 \n",
    "    \n",
    "    # generate w2v word embedding for altered mission statement\n",
    "    w2v_missionStatement = getWord2Vec_Embedding(missionStatement)\n",
    "    collect_Cosine_Values = []\n",
    "\n",
    "    for key, value in word2Vec_Embeddings_cleanedStatements.items():\n",
    "        \n",
    "        cosim = 1 - cosine(value, w2v_missionStatement)\n",
    "        collect_Cosine_Values.append([cosim, key])\n",
    "\n",
    "    value_list_sorted = sorted(collect_Cosine_Values, key=itemgetter(0))\n",
    "\n",
    "    if value_list_sorted[-1][1] == orgID:\n",
    "        correct_count += 1        \n",
    "    else:\n",
    "        incorrect_count += 1\n",
    "        \n",
    "percent = correct_count/(correct_count + incorrect_count) *100\n",
    "print(percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. This test is the same as in 2.2.1., except that the words are shuffled, so that strings from the original mission statement are not retained.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of in/correct matches\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "# loop over mission statements\n",
    "for k, v in missionStatements.items():\n",
    "\n",
    "    missionStatement = v[3]\n",
    "    orgID = k\n",
    "    \n",
    "    # Substitute fraction of mission statement with random words approximating noise\n",
    "    missionStatementWords_asList = missionStatement.split()\n",
    "\n",
    "    no_words = len(missionStatementWords_asList)\n",
    "    fraction_of_words = int(no_words * (1/2))\n",
    "\n",
    "    firstPart = missionStatementWords_asList[:fraction_of_words + 1]\n",
    "    secondPart = randomwordgenerator.generate_random_words(n = int(no_words * (1/2)))\n",
    " \n",
    "    # Version to shuffle the selected words\n",
    "    combinedParts = firstPart + secondPart\n",
    "    random.shuffle(combinedParts)\n",
    "    missionStatement = \" \".join(combinedParts)\n",
    "    \n",
    "    # generate w2v word embedding for altered mission statement\n",
    "    w2v_missionStatement = getWord2Vec_Embedding(missionStatement)\n",
    "    collect_Cosine_Values = []\n",
    "\n",
    "    for key, value in word2Vec_Embeddings_cleanedStatements.items():\n",
    "        \n",
    "        cosim = 1 - cosine(value, w2v_missionStatement)\n",
    "        collect_Cosine_Values.append([cosim, key])\n",
    "\n",
    "    value_list_sorted = sorted(collect_Cosine_Values, key=itemgetter(0))\n",
    "\n",
    "    if value_list_sorted[-1][1] == orgID:\n",
    "        correct_count += 1        \n",
    "    else:\n",
    "        incorrect_count += 1\n",
    "        \n",
    "percent = correct_count/(correct_count + incorrect_count) *100\n",
    "print(percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1. This test replaces the words in the original mission statement with synonyms. This test approximates how the algorithm handles cases where the meaning is retained but the actual words are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of in/correct matches\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "# loop over mission statements\n",
    "for k, v in missionStatements.items():\n",
    "\n",
    "    missionStatement = v[3]\n",
    "    orgID = k\n",
    "    \n",
    "    # block to generate synonyms\n",
    "    missionStatementWords_asList = missionStatement.split()\n",
    "    constructedMissionList = []\n",
    "    \n",
    "    for word in missionStatementWords_asList:\n",
    "        \n",
    "        synonyms = []\n",
    "        \n",
    "        for syn in wordnet.synsets(word):\n",
    "            for l in syn.lemmas():\n",
    "                synonyms.append(l.name())\n",
    "    \n",
    "        a = set(synonyms)\n",
    "        a = list(a)\n",
    "        \n",
    "        # replace with first synonym in wordnet\n",
    "        try:\n",
    "            constructedMissionList.append(a[0])\n",
    "        except:\n",
    "            constructedMissionList.append(\"\")\n",
    "         \n",
    "    constructed_missionStatement = \" \".join(constructedMissionList)\n",
    "    missionStatement = constructed_missionStatement\n",
    "    \n",
    "    # generate w2v word embedding for altered mission statement\n",
    "    w2v_missionStatement = getWord2Vec_Embedding(missionStatement)\n",
    "    collect_Cosine_Values = []\n",
    "\n",
    "    for key, value in word2Vec_Embeddings_cleanedStatements.items():\n",
    "        \n",
    "        cosim = 1 - cosine(value, w2v_missionStatement)\n",
    "        collect_Cosine_Values.append([cosim, key])\n",
    "\n",
    "    value_list_sorted = sorted(collect_Cosine_Values, key=itemgetter(0))\n",
    "\n",
    "    if value_list_sorted[-1][1] == orgID:\n",
    "        correct_count += 1        \n",
    "    else:\n",
    "        incorrect_count += 1\n",
    "        \n",
    "percent = correct_count/(correct_count + incorrect_count) *100\n",
    "print(percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. This is the same test as 2.3.1, except that no words that already exist in the mission statement are accepted. That is, if a synonym appears somewhere else in the mission statement, then this will not be considered an acceptable synonym. The procedure instead attempts to replace the word with the second or third synonym. The purpose is to attempt to retain meaning of the mission statement withou retaining any of the word tokens that were present in the original mission statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of in/correct matches\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "# loop over mission statements\n",
    "for k, v in missionStatements.items():\n",
    "\n",
    "    missionStatement = v[3]\n",
    "    orgID = k\n",
    "    \n",
    "    # retrieve synonym block\n",
    "    missionStatementWords_asList = missionStatement.split()\n",
    "    constructedMissionList = []\n",
    "    \n",
    "    for word in missionStatementWords_asList:\n",
    "        \n",
    "        synonyms = []\n",
    "        \n",
    "        for syn in wordnet.synsets(word):\n",
    "            for l in syn.lemmas():\n",
    "                synonyms.append(l.name())\n",
    "    \n",
    "        a = set(synonyms)\n",
    "        a = list(a)\n",
    "   \n",
    "        # Attempt to replace the word with the first three suggested synonyms by wordnet\n",
    "        # If the first one equals the word to be replaced or already occurs in mission statement\n",
    "        # then proceed to the second suggestion. If the first three suggestions do not mee the conditions\n",
    "        # or if there are no suggestions (except clause), then leave blank replacement      \n",
    "        \n",
    "        try:\n",
    "            if a[0] != word and a[0] not in missionStatementWords_asList:\n",
    "                constructedMissionList.append(a[0])\n",
    "            elif a[1] != word and a[1] not in missionStatementWords_asList:\n",
    "                constructedMissionList.append(a[1])\n",
    "            elif a[2] != word and a[2] not in missionStatementWords_asList:\n",
    "                constructedMissionList.append(a[2])\n",
    "            else:\n",
    "                #pass\n",
    "                constructedMissionList.append(\"\")\n",
    "        except:\n",
    "            constructedMissionList.append(\"\")\n",
    "         \n",
    "    constructed_missionStatement = \" \".join(constructedMissionList)\n",
    "    missionStatement = constructed_missionStatement\n",
    "\n",
    "    # generate w2v word embedding for altered mission statement\n",
    "    w2v_missionStatement = getWord2Vec_Embedding(missionStatement)\n",
    "    collect_Cosine_Values = []\n",
    "\n",
    "    for key, value in word2Vec_Embeddings_cleanedStatements.items():\n",
    "        \n",
    "        cosim = 1 - cosine(value, w2v_missionStatement)\n",
    "        collect_Cosine_Values.append([cosim, key])\n",
    "\n",
    "    value_list_sorted = sorted(collect_Cosine_Values, key=itemgetter(0))\n",
    "\n",
    "    if value_list_sorted[-1][1] == orgID:\n",
    "        correct_count += 1        \n",
    "    else:\n",
    "        incorrect_count += 1\n",
    "        \n",
    "percent = correct_count/(correct_count + incorrect_count) *100\n",
    "print(percent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
