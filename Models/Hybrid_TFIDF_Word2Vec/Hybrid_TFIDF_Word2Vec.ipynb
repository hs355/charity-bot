{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook contains Hybrid TFIDF and Word2Vec Embeddings Procedures on Pre-Trained and Custum Corpuses and Tests Performed on TFIDF-Word2Vec to Determine How it Performs on Text Similarity Tasks"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim import models\n",
    "from gensim import corpora\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from operator import itemgetter\n",
    "from scipy.spatial.distance import cosine\n",
    "from randomwordgenerator import randomwordgenerator\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/standard/Documents/Working/all_Combined_Cleaned_Ratings_Selection.pickle\"\n",
    "\n",
    "with open(filename, \"rb\") as handle:\n",
    "    missionStatements = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of documents and tokenize the words to feed to Gensim TFIDF Model\n",
    "documents = []\n",
    "for k, v in missionStatements.items():\n",
    "    documents.append(v[3]) # v[3] holds missions statements\n",
    "    \n",
    "texts = [\n",
    "        [word for word in document.split()] \n",
    "        for document in documents]\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store tfidf values of mission statment words\n",
    "tfidf = models.tfidfmodel.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "tfidf_values_missionStatements_dict = {}\n",
    "d = {}\n",
    "for doc in corpus_tfidf:\n",
    "    for id, value in doc:\n",
    "        word = dictionary.get(id)\n",
    "        tfidf_values_missionStatements_dict[word] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mission statements into a dataframe\n",
    "df_format = []\n",
    "\n",
    "for k, v in missionStatements.items():\n",
    "    df_format.append([k, v[3]])\n",
    "    \n",
    "df = pd.DataFrame(df_format, columns = ['orgID', 'missionStatement']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for words in df['missionStatement']:\n",
    "    corpus.append(words.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "EMBEDDING_FILE = '/Users/standard/Documents/Working/EDA2/GoogleNews-vectors-negative300.bin.gz'\n",
    "google_word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "\n",
    "# Training the corpus with Google Pretrained Model\n",
    "google_model = Word2Vec(size = 300, window = 5, min_count = 2, workers = -1)\n",
    "google_model.build_vocab(corpus)\n",
    "\n",
    "google_model.intersect_word2vec_format(EMBEDDING_FILE, lockf=1.0, binary=True)\n",
    "\n",
    "google_model.train(corpus, total_examples = google_model.corpus_count, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a Dictionary to Hold the Embeddings for each Mission Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to retrieve the hybrid tfidf-word2vec embedding\n",
    "def get_hybrid_tfidf_word2Vec_Embedding(text):\n",
    "    \n",
    "    avgword2vec = None\n",
    "    count = 0\n",
    "    \n",
    "    for word in text.split():\n",
    "        \n",
    "        if word in google_model.wv.vocab:\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "            if avgword2vec is None:\n",
    "                avgword2vec = np.dot(google_model[word], tfidf_values_missionStatements_dict[word])\n",
    "                \n",
    "            else:\n",
    "                avgword2vec = avgword2vec + (np.dot(google_model[word], tfidf_values_missionStatements_dict[word]))\n",
    "                \n",
    "    if avgword2vec is not None:\n",
    "        avgword2vec = avgword2vec / count\n",
    "        \n",
    "        return avgword2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the embeddings for each mission statement\n",
    "hybrid_tfidf_word2Vec_Embeddings = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "   \n",
    "    missionStatement = row['missionStatement']\n",
    "    orgID = row['orgID']\n",
    "    \n",
    "    vectors = get_hybrid_tfidf_word2Vec_Embedding\n",
    "    hybrid_tfidf_word2Vec_Embeddings[orgID] = vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing Section: This section presents several tests.\n",
    "\n",
    "### Specifically, what the tests do is to take a mission statement from a charity, manipulate the mission statement, e.g. delete parts, add noise, etc., and see if the altered mission statement is successfully matched with the organization's original/unaltered mission statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. This is just a check to see that everything works. The mission statement is not altered. The unaltered statement is matched with the closest mission statement (it should be itself)  - hundred percent match should be attained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of correct and incorrect matches\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "# loop through mission statements \n",
    "for k, v in missionStatements.items():\n",
    "\n",
    "    missionStatement = v[3]\n",
    "    orgID = k\n",
    "        \n",
    "    # generate embedding for mission statement\n",
    "    tfidf_w2v_missionStatement = get_hybrid_tfidf_word2Vec_Embedding(missionStatement)\n",
    "    collect_Cosine_Values = []\n",
    "\n",
    "    for key, value in hybrid_tfidf_word2Vec_Embeddings.items():\n",
    "        \n",
    "        cosim = 1 - cosine(value, tfidf_w2v_missionStatement)\n",
    "        collect_Cosine_Values.append([cosim, key])\n",
    "\n",
    "    # sort to attain highest cosine values\n",
    "    value_list_sorted = sorted(collect_Cosine_Values, key=itemgetter(0))\n",
    "    if value_list_sorted[-1][1] == orgID:\n",
    "        correct_count = correct_count + 1        \n",
    "    else:\n",
    "        incorrect_count = incorrect_count + 1\n",
    "        \n",
    "perc_correct = (correct_count / (correct_count+incorrect_count))*100\n",
    "print(perc_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. This is the first manipulation. A fraction of the mission statement is selected (either 1/2, 1/5, or 1/10) and then attempted to match with the closest unaltered mission statement. If it is matched with its unaltered version, it's recorded as a correct match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of correct and incorrect matches\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "# loop through mission statements \n",
    "for k, v in missionStatements.items():\n",
    "\n",
    "    missionStatement = v[3]\n",
    "    orgID = k\n",
    "    \n",
    "    # vary length of statement e.g. first half, first tenth, second half, etc\n",
    "    missionStatement_length = len(missionStatement)\n",
    "    missionStatement = missionStatement[:int(0.2*missionStatement_length)]\n",
    "        \n",
    "    # generate embedding for mission statement\n",
    "    tfidf_w2v_missionStatement = get_hybrid_tfidf_word2Vec_Embedding(missionStatement)\n",
    "    collect_Cosine_Values = []\n",
    "\n",
    "    for key, value in hybrid_tfidf_word2Vec_Embeddings.items():\n",
    "        \n",
    "        cosim = 1 - cosine(value, tfidf_w2v_missionStatement)\n",
    "        collect_Cosine_Values.append([cosim, key])\n",
    "\n",
    "    # sort to attain highest cosine values\n",
    "    value_list_sorted = sorted(collect_Cosine_Values, key=itemgetter(0))\n",
    "    if value_list_sorted[-1][1] == orgID:\n",
    "        correct_count = correct_count + 1        \n",
    "    else:\n",
    "        incorrect_count = incorrect_count + 1\n",
    "        \n",
    "perc_correct = (correct_count / (correct_count+incorrect_count))*100\n",
    "print(perc_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3. This test selects a random subset of words from the mission statement and only uses these words in its attempt to match with the correct un-altered mission statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of correct and incorrect matches\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "# loop through mission statements \n",
    "for k, v in missionStatements.items():\n",
    "\n",
    "    missionStatement = v[3]\n",
    "    orgID = k\n",
    "    \n",
    "    # block to select random subset of words from mission statement\n",
    "    missionStatementWords_asList = missionStatement.split()\n",
    "\n",
    "    # get number of words in mission statement\n",
    "    no_words = len(missionStatementWords_asList)\n",
    "    half_no_words = int(no_words*0.5)\n",
    "\n",
    "    # list to populate with random words from mission statement\n",
    "    select_Words_atRandom = []\n",
    "\n",
    "    while len(select_Words_atRandom) < half_no_words:\n",
    "\n",
    "        randno = random.randint(0, no_words-1)\n",
    "        word = missionStatementWords_asList[randno]\n",
    "\n",
    "        # Non-Unique Version \n",
    "        select_Words_atRandom.append(word)\n",
    "        \n",
    "        # Unique Version: if no duplicates should be in new statement use this version\n",
    "        #if word not in select_Words_atRandom:\n",
    "        #    select_Words_atRandom.append(word)\n",
    "        #else:\n",
    "        #    pass\n",
    "\n",
    "    constructed_missionStatement = \" \".join(select_Words_atRandom)\n",
    "    missionStatement = constructed_missionStatement\n",
    "        \n",
    "    # generate embedding for mission statement\n",
    "    tfidf_w2v_missionStatement = get_hybrid_tfidf_word2Vec_Embedding(missionStatement)\n",
    "    collect_Cosine_Values = []\n",
    "\n",
    "    for key, value in hybrid_tfidf_word2Vec_Embeddings.items():\n",
    "        \n",
    "        cosim = 1 - cosine(value, tfidf_w2v_missionStatement)\n",
    "        collect_Cosine_Values.append([cosim, key])\n",
    "\n",
    "    # sort to attain highest cosine values\n",
    "    value_list_sorted = sorted(collect_Cosine_Values, key=itemgetter(0))\n",
    "    if value_list_sorted[-1][1] == orgID:\n",
    "        correct_count = correct_count + 1        \n",
    "    else:\n",
    "        incorrect_count = incorrect_count + 1\n",
    "        \n",
    "perc_correct = (correct_count / (correct_count+incorrect_count))*100\n",
    "print(perc_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. This test attempts to measure how noise affects the algorithms performance. Fraction of the original mission statement is replaced with random words (noise). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of correct and incorrect matches\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "# loop through mission statements \n",
    "for k, v in missionStatements.items():\n",
    "\n",
    "    missionStatement = v[3]\n",
    "    orgID = k\n",
    "    \n",
    "    # substitute fraction of mission statement with random words to approximate noise\n",
    "    \n",
    "    missionStatementWords_asList = missionStatement.split()\n",
    "\n",
    "    no_words = len(missionStatementWords_asList)\n",
    "    fraction_of_words = int(no_words * (1/4))\n",
    "\n",
    "    firstPart = missionStatementWords_asList[:fraction_of_words + 1]\n",
    "    secondPart = randomwordgenerator.generate_random_words(n = int(no_words * (3/4)))\n",
    "\n",
    "    constructed_missionStatement1 = \" \".join(firstPart)\n",
    "    constructed_missionStatement2 = \" \".join(secondPart)\n",
    "    missionStatement = constructed_missionStatement1 + \" \" + constructed_missionStatement2 \n",
    "     \n",
    "    # generate embedding for mission statement\n",
    "    tfidf_w2v_missionStatement = get_hybrid_tfidf_word2Vec_Embedding(missionStatement)\n",
    "    collect_Cosine_Values = []\n",
    "\n",
    "    for key, value in hybrid_tfidf_word2Vec_Embeddings.items():\n",
    "        \n",
    "        cosim = 1 - cosine(value, tfidf_w2v_missionStatement)\n",
    "        collect_Cosine_Values.append([cosim, key])\n",
    "\n",
    "    # sort to attain highest cosine values\n",
    "    value_list_sorted = sorted(collect_Cosine_Values, key=itemgetter(0))\n",
    "    if value_list_sorted[-1][1] == orgID:\n",
    "        correct_count = correct_count + 1        \n",
    "    else:\n",
    "        incorrect_count = incorrect_count + 1\n",
    "        \n",
    "perc_correct = (correct_count / (correct_count+incorrect_count))*100\n",
    "print(perc_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. This test is the same as in 3.2.1., except that the words are shuffled, so that strings from the original mission statement are not retained.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of correct and incorrect matches\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "# loop through mission statements \n",
    "for k, v in missionStatements.items():\n",
    "\n",
    "    missionStatement = v[3]\n",
    "    orgID = k\n",
    "    \n",
    "    # substitute fraction of mission statement with random words to approximate noise\n",
    "    \n",
    "    missionStatementWords_asList = missionStatement.split()\n",
    "\n",
    "    no_words = len(missionStatementWords_asList)\n",
    "    fraction_of_words = int(no_words * (1/4))\n",
    "\n",
    "    firstPart = missionStatementWords_asList[:fraction_of_words + 1]\n",
    "    secondPart = randomwordgenerator.generate_random_words(n = int(no_words * (3/4)))\n",
    "\n",
    "    # Version to shuffle the selected words\n",
    "    combinedParts = firstPart + secondPart\n",
    "    random.shuffle(combinedParts)\n",
    "    missionStatement = \" \".join(combinedParts)\n",
    "     \n",
    "    # generate embedding for mission statement\n",
    "    tfidf_w2v_missionStatement = get_hybrid_tfidf_word2Vec_Embedding(missionStatement)\n",
    "    collect_Cosine_Values = []\n",
    "\n",
    "    for key, value in hybrid_tfidf_word2Vec_Embeddings.items():\n",
    "        \n",
    "        cosim = 1 - cosine(value, tfidf_w2v_missionStatement)\n",
    "        collect_Cosine_Values.append([cosim, key])\n",
    "\n",
    "    # sort to attain highest cosine values\n",
    "    value_list_sorted = sorted(collect_Cosine_Values, key=itemgetter(0))\n",
    "    if value_list_sorted[-1][1] == orgID:\n",
    "        correct_count = correct_count + 1        \n",
    "    else:\n",
    "        incorrect_count = incorrect_count + 1\n",
    "        \n",
    "perc_correct = (correct_count / (correct_count+incorrect_count))*100\n",
    "print(perc_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. This test replaces the words in the original mission statement with synonyms. This test approximates how the algorithm handles cases where the meaning is retained but the actual words are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of correct and incorrect matches\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "# loop through mission statements \n",
    "for k, v in missionStatements.items():\n",
    "\n",
    "    missionStatement = v[3]\n",
    "    orgID = k\n",
    "        \n",
    "    # replace with synonyms block\n",
    "    missionStatementWords_asList = missionStatement.split()\n",
    "    constructedMissionList = []\n",
    "    \n",
    "    for word in missionStatementWords_asList:\n",
    "        \n",
    "        synonyms = []\n",
    "        \n",
    "        for syn in wordnet.synsets(word):\n",
    "            for l in syn.lemmas():\n",
    "                synonyms.append(l.name())\n",
    "    \n",
    "        a = set(synonyms)\n",
    "        a = list(a)\n",
    "        \n",
    "        # replace with first synonym\n",
    "        try:\n",
    "            constructedMissionList.append(a[0])\n",
    "        except:\n",
    "            constructedMissionList.append(\"\")\n",
    "         \n",
    "    constructed_missionStatement = \" \".join(constructedMissionList)\n",
    "    missionStatement = constructed_missionStatement\n",
    "     \n",
    "    # generate embedding for mission statement\n",
    "    tfidf_w2v_missionStatement = get_hybrid_tfidf_word2Vec_Embedding(missionStatement)\n",
    "    collect_Cosine_Values = []\n",
    "\n",
    "    for key, value in hybrid_tfidf_word2Vec_Embeddings.items():\n",
    "        \n",
    "        cosim = 1 - cosine(value, tfidf_w2v_missionStatement)\n",
    "        collect_Cosine_Values.append([cosim, key])\n",
    "\n",
    "    # sort to attain highest cosine values\n",
    "    value_list_sorted = sorted(collect_Cosine_Values, key=itemgetter(0))\n",
    "    if value_list_sorted[-1][1] == orgID:\n",
    "        correct_count = correct_count + 1        \n",
    "    else:\n",
    "        incorrect_count = incorrect_count + 1\n",
    "        \n",
    "perc_correct = (correct_count / (correct_count+incorrect_count))*100\n",
    "print(perc_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. This is the same test as 3.3.1, except that no words that already exist in the mission statement are accepted. That is, if a synonym appears somewhere else in the mission statement, then this will not be considered an acceptable synonym. The procedure instead attempts to replace the word with the second or third synonym. The purpose is to attempt to retain meaning of the mission statement withou retaining any of the word tokens that were present in the original mission statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of correct and incorrect matches\n",
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "# loop through mission statements \n",
    "for k, v in missionStatements.items():\n",
    "\n",
    "    missionStatement = v[3]\n",
    "    orgID = k\n",
    "        \n",
    "    # replace with synonyms block\n",
    "    missionStatementWords_asList = missionStatement.split()\n",
    "    constructedMissionList = []\n",
    "    \n",
    "    for word in missionStatementWords_asList:\n",
    "        \n",
    "        synonyms = []\n",
    "        \n",
    "        for syn in wordnet.synsets(word):\n",
    "            for l in syn.lemmas():\n",
    "                synonyms.append(l.name())\n",
    "    \n",
    "        a = set(synonyms)\n",
    "        a = list(a)\n",
    "\n",
    "        # Attempt to replace the word with the first three suggested synonyms by wordnet\n",
    "        # If the first one equals the word to be replaced or already occurs in mission statement\n",
    "        # then proceed to the second suggestion. If the first three suggestions do not mee the conditions\n",
    "        # or if there are no suggestions (except clause), then leave blank replacement      \n",
    "        try:\n",
    "            if a[0] != word and a[0] not in missionStatementWords_asList:\n",
    "                constructedMissionList.append(a[0])\n",
    "            elif a[1] != word and a[1] not in missionStatementWords_asList:\n",
    "                constructedMissionList.append(a[1])\n",
    "            elif a[2] != word and a[2] not in missionStatementWords_asList:\n",
    "                constructedMissionList.append(a[2])\n",
    "            else:\n",
    "                #pass\n",
    "                constructedMissionList.append(\"\")\n",
    "        except:\n",
    "            constructedMissionList.append(\"\")\n",
    "         \n",
    "    constructed_missionStatement = \" \".join(constructedMissionList)\n",
    "    missionStatement = constructed_missionStatement\n",
    "     \n",
    "    # generate embedding for mission statement\n",
    "    tfidf_w2v_missionStatement = get_hybrid_tfidf_word2Vec_Embedding(missionStatement)\n",
    "    collect_Cosine_Values = []\n",
    "\n",
    "    for key, value in hybrid_tfidf_word2Vec_Embeddings.items():\n",
    "        \n",
    "        cosim = 1 - cosine(value, tfidf_w2v_missionStatement)\n",
    "        collect_Cosine_Values.append([cosim, key])\n",
    "\n",
    "    # sort to attain highest cosine values\n",
    "    value_list_sorted = sorted(collect_Cosine_Values, key=itemgetter(0))\n",
    "    if value_list_sorted[-1][1] == orgID:\n",
    "        correct_count = correct_count + 1        \n",
    "    else:\n",
    "        incorrect_count = incorrect_count + 1\n",
    "        \n",
    "perc_correct = (correct_count / (correct_count+incorrect_count))*100\n",
    "print(perc_correct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
