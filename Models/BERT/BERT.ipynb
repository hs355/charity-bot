{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook contains BERT Embedding Procedures on Pre-Trained and Custum Corpuses and Tests Performed on BERT to Determine How it Performs on Text Similarity Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from operator import itemgetter\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT Model Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Bert pre-trained model\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n",
    "\n",
    "# Fine tune model\n",
    "from simpletransformers.language_modeling import LanguageModelingModel\n",
    "import logging\n",
    "\n",
    "for k, v in missionStatements.items():\n",
    "    sent = v[3].replace(\".\", \" [SEP]\")\n",
    "    if sent[-5:] != \"[SEP]\":\n",
    "        sent = sent + \"[SEP]\"\n",
    "        \n",
    "    f = open(\"text.txt\", \"a\")\n",
    "    f.write(sent)\n",
    "\n",
    "f.close()\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "train_args = {\n",
    "    \"reprocess_input_data\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "}\n",
    "\n",
    "model = LanguageModelingModel('bert', 'bert-base-cased', args=train_args, use_cuda=False)\n",
    "model.train_model(\"train.txt\", eval_file=\"text.txt\")\n",
    "model.eval_model(\"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get Bert Word Embeddings\n",
    "\n",
    "def getBertEmbedding(text1):\n",
    "    \n",
    "    # BERT expects text input in this format \n",
    "    marked_text1 = \"[CLS] \" + text1 + \" [SEP]\" #this takes entire statement as one sentence\n",
    "        \n",
    "    # Split the sentences into tokens\n",
    "    tokenized_text1 = tokenizer.tokenize(marked_text1)\n",
    "    \n",
    "    # Map the token strings to their vocabulary indeces\n",
    "    indexed_tokens1 = tokenizer.convert_tokens_to_ids(tokenized_text1)\n",
    "    \n",
    "    # Mark each of the tokens as belonging to sentence \"1\"\n",
    "    segments_ids1 = [1] * len(tokenized_text1)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor1 = torch.tensor([indexed_tokens1])\n",
    "    segments_tensors1 = torch.tensor([segments_ids1])\n",
    "\n",
    "    # Run the text through BERT, and collect all of the hidden states produced\n",
    "    # from all 12 layers\n",
    "    with torch.no_grad():\n",
    "\n",
    "        outputs1 = model(tokens_tensor1, segments_tensors1)\n",
    "\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        hidden_states1 = outputs1[2]\n",
    "\n",
    "   \n",
    "    # Concatenate the tensors for all layers. Use 'stack' to\n",
    "    # create a new dimension in the tensor.\n",
    "\n",
    "    token_embeddings1 = torch.stack(hidden_states1, dim=0)\n",
    "    #token_embeddings1.size()\n",
    "\n",
    "    # Remove dimension 1, the \"batches\".\n",
    "    token_embeddings1 = torch.squeeze(token_embeddings1, dim=1)\n",
    "    #token_embeddings.size()\n",
    "   \n",
    "    # Swap dimensions 0 and 1.\n",
    "    token_embeddings1 = token_embeddings1.permute(1,0,2)\n",
    "    #token_embeddings1.size()\n",
    "\n",
    "    # hidden_states has shape [13 x 1 x 22 x 768]\n",
    "    # token_vecs is a tensor with shape [22 x 768]\n",
    "    token_vecs1 = hidden_states1[-2][0]\n",
    "    \n",
    "    # Calculate the average of all token vectors.\n",
    "    sentence_embedding1 = torch.mean(token_vecs1, dim=0)\n",
    "    \n",
    "    return sentence_embedding1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create BERT Embeddings Dictionaries for Mission Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embeddings = {}\n",
    "\n",
    "for key, value in missionStatements.items():\n",
    "\n",
    "    orgID = key\n",
    "    text2 = value[3]\n",
    "    \n",
    "    BertEmbedding = getBertEmbedding(text2)\n",
    "    bert_embeddings[orgID] = BertEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing Section: This section presents several tests. In order to run on different models, substitute in the appropriate dictionaries from Section 1. \n",
    "\n",
    "### Specifically, what the tests do is to take a mission statement from a charity, manipulate the mission statement, e.g. delete parts, add noise, etc., and see if the altered mission statement is successfully matched with the organization's original/unaltered mission statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "from randomwordgenerator import randomwordgenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. This is just a check to see that everything works. The mission statement is not altered. The unaltered statement is matched with the closest mission statement (it should be itself)  - hundred percent match should be attained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "\n",
    "for k, v in missionStatements.items():\n",
    "    \n",
    "    orgID = k\n",
    "    statement = v[3]\n",
    "    \n",
    "    # generate BERT embedding of input mission statement\n",
    "    bert_statement = getBertEmbedding(statement)\n",
    "    collect_Cosine = []\n",
    "    \n",
    "\n",
    "    for key, value in bert_embeddings.items():                \n",
    "        \n",
    "        # Calculate the cosine similarity between two inputs \n",
    "        cosim = 1 - cosine(value, bert_statementL)\n",
    "        collect_Cosine.append([cosim, key])\n",
    "            \n",
    "    value_list_sorted = sorted(collect_Cosine, key=itemgetter(0))\n",
    "    \n",
    "    if value_list_sorted[-1][1] == orgIDL:\n",
    "        correct_count += 1.0\n",
    "    else:\n",
    "        incorrect_count += 1.0\n",
    "        \n",
    "perc_correct = (correct_count / (correct_count+incorrect_count))*100\n",
    "print(perc_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. This is the first manipulation. A fraction of the mission statement is selected (either 1/2, 1/5, or 1/10) and then attempted to match with the closest unaltered mission statement. If it is matched with its unaltered version, it's recorded as a correct match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "\n",
    "for k, v in missionStatements.items():\n",
    "    \n",
    "    orgID = k\n",
    "    statement = v[3]\n",
    "    \n",
    "    lenStatement = len(statementL)\n",
    "    bert_statement = bert_statement[:int(0.5*lenStatement)]\n",
    "    \n",
    "    # generate BERT embedding of input mission statement\n",
    "    bert_statement = getBertEmbedding(statement)\n",
    "    collect_Cosine = []\n",
    "    \n",
    "    for key, value in bert_embeddings.items():                \n",
    "        \n",
    "        # Calculate the cosine similarity between two inputs \n",
    "        cosim = 1 - cosine(value, bert_statementL)\n",
    "        collect_Cosine.append([cosim, key])\n",
    "           \n",
    "    # sort cosine values\n",
    "    value_list_sorted = sorted(collect_Cosine, key=itemgetter(0))\n",
    "    \n",
    "    if value_list_sorted[-1][1] == orgIDL:\n",
    "        correct_count += 1.0\n",
    "    else:\n",
    "        incorrect_count += 1.0\n",
    "        \n",
    "perc_correct = (correct_count / (correct_count+incorrect_count))*100\n",
    "print(perc_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. This test selects a random subset of words from the mission statement and only uses these words in its attempt to match with the correct un-altered mission statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "\n",
    "for k, v in missionStatements.items():\n",
    "    \n",
    "    orgID = k\n",
    "    statement = v[3]\n",
    "    \n",
    "    # select random subset of words from mission statement block starts here\n",
    "    # convert mission statement into list of words\n",
    "    missionStatementWords_asList = statementL.split()\n",
    "\n",
    "    # get number of words in mission statement\n",
    "    no_words = len(missionStatementWords_asList)\n",
    "    half_no_words = int(no_words*0.5)\n",
    "\n",
    "    # list to populate with random words from mission statement\n",
    "    select_Words_atRandom = []\n",
    "\n",
    "    while len(select_Words_atRandom) < half_no_words:\n",
    "\n",
    "        randno = random.randint(0, no_words-1)\n",
    "        word = missionStatementWords_asList[randno]\n",
    "\n",
    "        # Non-Unique Version \n",
    "        select_Words_atRandom.append(word)\n",
    "        \n",
    "        # Unique Words Version: this version prevents duplicate words to be in new statement\n",
    "        #if word not in select_Words_atRandom:\n",
    "        #    select_Words_atRandom.append(word)\n",
    "        #else:\n",
    "        #    pass\n",
    "\n",
    "    constructed_missionStatement = \" \".join(select_Words_atRandom)\n",
    "    statement = constructed_missionStatement\n",
    "    \n",
    "    # generate BERT embedding of input mission statement\n",
    "    bert_statement = getBertEmbedding(statement)\n",
    "    collect_Cosine = []\n",
    "    \n",
    "    for key, value in bert_embeddings.items():                \n",
    "        \n",
    "        # Calculate the cosine similarity between two inputs \n",
    "        cosim = 1 - cosine(value, bert_statementL)\n",
    "        collect_Cosine.append([cosim, key])\n",
    "           \n",
    "    # sort cosine values\n",
    "    value_list_sorted = sorted(collect_Cosine, key=itemgetter(0))\n",
    "    \n",
    "    if value_list_sorted[-1][1] == orgIDL:\n",
    "        correct_count += 1.0\n",
    "    else:\n",
    "        incorrect_count += 1.0\n",
    "        \n",
    "perc_correct = (correct_count / (correct_count+incorrect_count))*100\n",
    "print(perc_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. This test attempts to measure how noise affects the algorithms performance. Fraction of the original mission statement is replaced with random words (noise). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "\n",
    "for k, v in missionStatements.items():\n",
    "    \n",
    "    orgID = k\n",
    "    statement = v[3]\n",
    "    \n",
    "    # substitute fraction of mission statement with random words approximating noise\n",
    "    missionStatementWords_asList = statement.split()\n",
    "\n",
    "    no_words = len(missionStatementWords_asList)\n",
    "    fraction_of_words = int(no_words * (1/2))\n",
    "\n",
    "    firstPart = missionStatementWords_asList[:fraction_of_words + 1]\n",
    "    secondPart = randomwordgenerator.generate_random_words(n = int(no_words * (1/2)))\n",
    "\n",
    "    # Default Version\n",
    "    constructed_missionStatement1 = \" \".join(firstPart)\n",
    "    constructed_missionStatement2 = \" \".join(secondPart)\n",
    "    missionStatement = constructed_missionStatement1 + \" \" + constructed_missionStatement2 \n",
    "    statement = missionStatement\n",
    "    \n",
    "    # generate BERT embedding of input mission statement\n",
    "    bert_statement = getBertEmbedding(statement)\n",
    "    collect_Cosine = []\n",
    "    \n",
    "    for key, value in bert_embeddings.items():                \n",
    "        \n",
    "        # Calculate the cosine similarity between two inputs \n",
    "        cosim = 1 - cosine(value, bert_statementL)\n",
    "        collect_Cosine.append([cosim, key])\n",
    "           \n",
    "    # sort cosine values\n",
    "    value_list_sorted = sorted(collect_Cosine, key=itemgetter(0))\n",
    "    \n",
    "    if value_list_sorted[-1][1] == orgIDL:\n",
    "        correct_count += 1.0\n",
    "    else:\n",
    "        incorrect_count += 1.0\n",
    "        \n",
    "perc_correct = (correct_count / (correct_count+incorrect_count))*100\n",
    "print(perc_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. This test is the same as in 2.2.1., except that the words are shuffled, so that strings from the original mission statement are not retained.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "\n",
    "for k, v in missionStatements.items():\n",
    "    \n",
    "    orgID = k\n",
    "    statement = v[3]\n",
    "    \n",
    "    # substitute fraction of mission statement with random words approximating noise\n",
    "    missionStatementWords_asList = statement.split()\n",
    "\n",
    "    no_words = len(missionStatementWords_asList)\n",
    "    fraction_of_words = int(no_words * (1/2))\n",
    "\n",
    "    firstPart = missionStatementWords_asList[:fraction_of_words + 1]\n",
    "    secondPart = randomwordgenerator.generate_random_words(n = int(no_words * (1/2)))\n",
    "    \n",
    "    # Version to shuffle the selected words\n",
    "    combinedParts = firstPart + secondPart\n",
    "    random.shuffle(combinedParts)\n",
    "    missionStatement = \" \".join(combinedParts)\n",
    "    statement = missionStatement\n",
    "    \n",
    "    # generate BERT embedding of input mission statement\n",
    "    bert_statement = getBertEmbedding(statement)\n",
    "    collect_Cosine = []\n",
    "    \n",
    "    for key, value in bert_embeddings.items():                \n",
    "        \n",
    "        # Calculate the cosine similarity between two inputs \n",
    "        cosim = 1 - cosine(value, bert_statementL)\n",
    "        collect_Cosine.append([cosim, key])\n",
    "           \n",
    "    # sort cosine values\n",
    "    value_list_sorted = sorted(collect_Cosine, key=itemgetter(0))\n",
    "    \n",
    "    if value_list_sorted[-1][1] == orgIDL:\n",
    "        correct_count += 1.0\n",
    "    else:\n",
    "        incorrect_count += 1.0\n",
    "        \n",
    "perc_correct = (correct_count / (correct_count+incorrect_count))*100\n",
    "print(perc_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1. This test replaces the words in the original mission statement with synonyms. This test approximates how the algorithm handles cases where the meaning is retained but the actual words are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "\n",
    "for k, v in missionStatements.items():\n",
    "    \n",
    "    orgID = k\n",
    "    statement = v[3]\n",
    "    \n",
    "    # generate synonyms: start of block\n",
    "    missionStatementWords_asList = statement.split()\n",
    "    constructedMissionList = []\n",
    "    \n",
    "    for word in missionStatementWords_asList:\n",
    "        \n",
    "        synonyms = []\n",
    "        \n",
    "        for syn in wordnet.synsets(word):\n",
    "            for l in syn.lemmas():\n",
    "                synonyms.append(l.name())\n",
    "    \n",
    "        a = set(synonyms)\n",
    "        a = list(a)\n",
    "        \n",
    "        # replace word in mission statement with first synonym\n",
    "        try:\n",
    "            constructedMissionList.append(a[0])\n",
    "        except:\n",
    "            constructedMissionList.append(\"\")\n",
    "        \n",
    "    \n",
    "   \n",
    "        # Attempt to replace the word with the first three suggested synonyms by wordnet\n",
    "        # If the first one equals the word to be replaced or already occurs in mission statement\n",
    "        # then proceed to the second suggestion. If the first three suggestions do not mee the conditions\n",
    "        # or if there are no suggestions (except clause), then leave blank replacement      \n",
    "        \n",
    "        #try:\n",
    "        #    if a[0] != word and a[0] not in missionStatementWords_asList:\n",
    "        #        constructedMissionList.append(a[0])\n",
    "        #    elif a[1] != word and a[1] not in missionStatementWords_asList:\n",
    "        #        constructedMissionList.append(a[1])\n",
    "        #    elif a[2] != word and a[2] not in missionStatementWords_asList:\n",
    "        #        constructedMissionList.append(a[2])\n",
    "        #    else:\n",
    "        #        #pass\n",
    "        #        constructedMissionList.append(\"\")\n",
    "        #except:\n",
    "        #    constructedMissionList.append(\"\")\n",
    "        \n",
    "    constructed_missionStatement = \" \".join(constructedMissionList)\n",
    "    statement = constructed_missionStatement\n",
    "\n",
    "    # generate BERT embedding of input mission statement\n",
    "    bert_statement = getBertEmbedding(statement)\n",
    "    collect_Cosine = []\n",
    "    \n",
    "    for key, value in bert_embeddings.items():                \n",
    "        \n",
    "        # Calculate the cosine similarity between two inputs \n",
    "        cosim = 1 - cosine(value, bert_statementL)\n",
    "        collect_Cosine.append([cosim, key])\n",
    "           \n",
    "    # sort cosine values\n",
    "    value_list_sorted = sorted(collect_Cosine, key=itemgetter(0))\n",
    "    \n",
    "    if value_list_sorted[-1][1] == orgIDL:\n",
    "        correct_count += 1.0\n",
    "    else:\n",
    "        incorrect_count += 1.0\n",
    "        \n",
    "perc_correct = (correct_count / (correct_count+incorrect_count))*100\n",
    "print(perc_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. This is the same test as 2.3.1, except that no words that already exist in the mission statement are accepted. That is, if a synonym appears somewhere else in the mission statement, then this will not be considered an acceptable synonym. The procedure instead attempts to replace the word with the second or third synonym. The purpose is to attempt to retain meaning of the mission statement withou retaining any of the word tokens that were present in the original mission statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "incorrect_count = 0\n",
    "\n",
    "\n",
    "for k, v in missionStatements.items():\n",
    "    \n",
    "    orgID = k\n",
    "    statement = v[3]\n",
    "    \n",
    "    # generate synonyms: start of block\n",
    "    missionStatementWords_asList = statement.split()\n",
    "    constructedMissionList = []\n",
    "    \n",
    "    for word in missionStatementWords_asList:\n",
    "        \n",
    "        synonyms = []\n",
    "        \n",
    "        for syn in wordnet.synsets(word):\n",
    "            for l in syn.lemmas():\n",
    "                synonyms.append(l.name())\n",
    "    \n",
    "        a = set(synonyms)\n",
    "        a = list(a)\n",
    "           \n",
    "        # Attempt to replace the word with the first three suggested synonyms by wordnet\n",
    "        # If the first one equals the word to be replaced or already occurs in mission statement\n",
    "        # then proceed to the second suggestion. If the first three suggestions do not mee the conditions\n",
    "        # or if there are no suggestions (except clause), then leave blank replacement      \n",
    "        \n",
    "        try:\n",
    "            if a[0] != word and a[0] not in missionStatementWords_asList:\n",
    "                constructedMissionList.append(a[0])\n",
    "            elif a[1] != word and a[1] not in missionStatementWords_asList:\n",
    "                constructedMissionList.append(a[1])\n",
    "            elif a[2] != word and a[2] not in missionStatementWords_asList:\n",
    "                constructedMissionList.append(a[2])\n",
    "            else:\n",
    "                #pass\n",
    "                constructedMissionList.append(\"\")\n",
    "        except:\n",
    "            constructedMissionList.append(\"\")\n",
    "        \n",
    "    constructed_missionStatement = \" \".join(constructedMissionList)\n",
    "    statement = constructed_missionStatement\n",
    "\n",
    "    # generate BERT embedding of input mission statement\n",
    "    bert_statement = getBertEmbedding(statement)\n",
    "    collect_Cosine = []\n",
    "    \n",
    "    for key, value in bert_embeddings.items():                \n",
    "        \n",
    "        # Calculate the cosine similarity between two inputs \n",
    "        cosim = 1 - cosine(value, bert_statementL)\n",
    "        collect_Cosine.append([cosim, key])\n",
    "           \n",
    "    # sort cosine values\n",
    "    value_list_sorted = sorted(collect_Cosine, key=itemgetter(0))\n",
    "    \n",
    "    if value_list_sorted[-1][1] == orgIDL:\n",
    "        correct_count += 1.0\n",
    "    else:\n",
    "        incorrect_count += 1.0\n",
    "        \n",
    "perc_correct = (correct_count / (correct_count+incorrect_count))*100\n",
    "print(perc_correct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
